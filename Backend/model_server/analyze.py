import re
from typing import List

from models import FeedbackItem
from sentence_transformers import SentenceTransformer, util
from transformers import pipeline
from concurrent.futures import ThreadPoolExecutor


# 1. ëª¨ë¸ ë¡œë”© (FastAPI ì‹œì‘ ì‹œ 1íšŒ)
model = SentenceTransformer('jhgan/ko-sbert-nli')
generator = pipeline('text-generation', model='skt/kogpt2-base-v2')    # íŒŒì´í”„ ë¼ì¸ ì‚¬ìš© EleutherAI/polyglot-ko-1.3b


def split_sentences(text: str) -> List[str]:
    return [s.strip() for s in text.split('.') if s.strip()]


def parse_generated_result(text: str) -> tuple[str, str]:
    rec, reason = '', ''
    try:
        rec_match = re.search(r"ì¶”ì²œ ë¬¸ì¥[:ï¼š]\s*(.+)", text)
        reason_match = re.search(r"ì´ìœ [:ï¼š]\s*(.+)", text)

        if rec_match:
            rec = rec_match.group(1).strip()
        if reason_match:
            reason = reason_match.group(1).strip()
            
        # ğŸ’¡ ì¡°ê±´ ê°•í™”: ì˜ë¯¸ ì—†ëŠ” í…ìŠ¤íŠ¸ëŠ” ì œê±°
        if rec.lower() in ["ì´ìœ :", "", "ë‚´ìš© ì—†ìŒ"] or rec.startswith("ì´ìœ "):
            rec = ""
        if reason.strip().startswith("#") or len(reason.strip()) < 5:
            reason = ""    
            
    except Exception as e:
        print(f"[âŒ íŒŒì‹± ì˜¤ë¥˜] {e}")
        print(f"[ğŸ“„ ì›ë³¸ ì‘ë‹µ] {text}")
        
    return rec, reason


def generate_prompt(original: str, jd: str) -> str:
    return f"""
    [ìê¸°ì†Œê°œì„œ ë¬¸ì¥]
    {original}

    [ì§ë¬´ ì„¤ëª…]
    {jd}

    ìœ„ ìê¸°ì†Œê°œì„œ ë¬¸ì¥ì´ ì§ë¬´ ì„¤ëª…ê³¼ ì˜ ë§ì§€ ì•ŠëŠ”ë‹¤ë©´, ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µí•´ì£¼ì„¸ìš”.

    [ì¶”ì²œ ë¬¸ì¥]
    (ì§ë¬´ ì„¤ëª…ê³¼ ì˜ ë§ë„ë¡ ë¬¸ì¥ì„ ê³ ì³ì£¼ì„¸ìš”)

    [ì´ìœ ]
    (ì™œ ê³ ì³ì•¼ í•˜ëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”)
    """


def generate_feedback(prompt: str) -> tuple[str, str]:
    try:
        result = generator(prompt, max_new_tokens=150, do_sample=True, temperature=0.9)[0]["generated_text"]
        print(result)
        
        rec, reason = parse_generated_result(result)

        # âœ… fallback ê°’ ì ìš© (ì´ ë¶€ë¶„!)
        if not rec:
            rec = "JDì— ë§ê²Œ êµ¬ì²´ì ì¸ í”„ë¡œì íŠ¸ ê²½í—˜ì„ ì‘ì„±í•´ë³´ì„¸ìš”."
        if not reason:
            reason = "ì§ë¬´ ì—°ê´€ì„±ì´ ë¶€ì¡±í•˜ê±°ë‚˜ ë„ˆë¬´ ì¶”ìƒì ì¸ í‘œí˜„ì…ë‹ˆë‹¤."
            
        if not rec or not reason:
            print(f"[âš ï¸ ì¶”ì²œ ìƒì„± ë¶€ì¡±] rec: '{rec}', reason: '{reason}'")

        print("[ğŸ“¥ LLM ì‘ë‹µ]", result)
        print("[âœ… íŒŒì‹±ëœ ê²°ê³¼]", rec, reason)
        
        return rec, reason

    except Exception as e:
        print(f"[LLM ìƒì„± ì‹¤íŒ¨] {e}")
        return "JDì— ë§ê²Œ êµ¬ì²´ì ì¸ í”„ë¡œì íŠ¸ ê²½í—˜ì„ ì‘ì„±í•´ë³´ì„¸ìš”.", "ì§ë¬´ ì—°ê´€ì„±ì´ ë¶€ì¡±í•˜ê±°ë‚˜ ë„ˆë¬´ ì¶”ìƒì ì¸ í‘œí˜„ì…ë‹ˆë‹¤."



def analyze_similarity(cover_letter: str, job_description: str) -> List[FeedbackItem]:
    sentences = split_sentences(cover_letter)
    jd_embedding = model.encode(job_description, convert_to_tensor=True)

    feedbacks = []
    weak_prompts = []
    weak_indexes = []

    # 1. ìœ ì‚¬ë„ ê³„ì‚° & ì•½í•œ ë¬¸ì¥ ì¶”ë¦¬ê¸°
    for idx, sent in enumerate(sentences):
        sent_embedding = model.encode(sent, convert_to_tensor=True)
        score = float(util.cos_sim(sent_embedding, jd_embedding)[0][0])
        is_weak = score < 0.7

        feedback = FeedbackItem(
            original_sentence=sent,
            similarity_score=score,
            is_weak=is_weak,
            recommendation="",
            reason=""
        )

        feedbacks.append(feedback)

        if is_weak:
            prompt = generate_prompt(sent, job_description)
            weak_prompts.append(prompt)
            weak_indexes.append(idx)

    # 2. ë³‘ë ¬ë¡œ LLM í˜¸ì¶œ
    if weak_prompts:
        with ThreadPoolExecutor() as executor:
            results = list(executor.map(generate_feedback, weak_prompts))

        for idx, (rec, reason) in zip(weak_indexes, results):
            feedbacks[idx].recommendation = rec
            feedbacks[idx].reason = reason

    return feedbacks


# # 2. ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ëŠ” í•¨ìˆ˜
# def split_sentences(text: str) -> List[str]:
#     return [s.strip() for s in text.split('.') if s.strip()]


# # 3. ìƒì„±ëœ LLM ê²°ê³¼ì—ì„œ ì¶”ì²œ ë¬¸ì¥ + ì´ìœ  ì¶”ì¶œ
# def parse_generated_result(text: str) -> tuple[str, str]:
#     rec, reason = '', ''
#     try:
#         rec_match = re.search(r"ì¶”ì²œ ë¬¸ì¥[:ï¼š]\s*(.+)", text)
#         reason_match = re.search(r"ì´ìœ [:ï¼š]\s*(.+)", text)

#         if rec_match:
#             rec = rec_match.group(1).strip()
#         if reason_match:
#             reason = reason_match.group(1).strip()
#     except Exception as e:
#         print(f"[íŒŒì‹± ì˜¤ë¥˜] {e}")
#         print(f"[ì›ë³¸ ì‘ë‹µ] {text}")

#     return rec, reason


# # 4. LLM ê¸°ë°˜ ì¶”ì²œ ë¬¸ì¥ + ì´ìœ  ìƒì„± í•¨ìˆ˜
# def generate_feedback(original: str, jd: str) -> tuple[str, str]:
#     prompt = f"""
#     ìê¸°ì†Œê°œì„œ ë¬¸ì¥: "{original}"
#     ì§ë¬´ ì„¤ëª…: "{jd}"

#     ì´ ìê¸°ì†Œê°œì„œ ë¬¸ì¥ì´ JDì— ì˜ ë§ì§€ ì•ŠëŠ”ë‹¤ë©´, ê³ ì¹œ ë¬¸ì¥ê³¼ ê·¸ ì´ìœ ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.

#     ë‹¤ìŒ í˜•ì‹ì— ë§ì¶° ì£¼ì„¸ìš”:

#     ì¶”ì²œ ë¬¸ì¥: ...
#     ì´ìœ : ...
#     """

#     try:
#         result = generator(prompt, max_new_tokens=150, do_sample=True, temperature=0.9)[0]["generated_text"]
#         return parse_generated_result(result)
    
#     except Exception as e:
#         print(f"[LLM ìƒì„± ì‹¤íŒ¨] {e}")
#         return "JDì™€ ê´€ë ¨ëœ êµ¬ì²´ì ì¸ ê²½í—˜ìœ¼ë¡œ ë³´ì™„í•´ë³´ì„¸ìš”.", "ì§ë¬´ ì—°ê´€ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤."



# # 4. ìµœì¢… ë¶„ì„ í•¨ìˆ˜
# def analyze_similarity(cover_letter: str, job_description: str) -> List[FeedbackItem]:
#     cl_sentences = split_sentences(cover_letter)
#     jd_embedding = model.encode(job_description, convert_to_tensor=True)

#     feedbacks = []
#     for sent in cl_sentences:
#         sent_embedding = model.encode(sent, convert_to_tensor=True)
#         score = float(util.cos_sim(sent_embedding, jd_embedding)[0][0])
#         is_weak = score < 0.7

#         recommendation = ""
#         reason = ""

#         if is_weak:
#              recommendation, reason = generate_feedback(sent, job_description)

#         feedbacks.append(FeedbackItem(
#             original_sentence=sent,
#             similarity_score=score,
#             is_weak=is_weak,
#             recommendation=recommendation,
#             reason=reason
#         ))

#     return feedbacks
