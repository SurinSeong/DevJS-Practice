import re
from typing import Tuple
from typing import List

from models import FeedbackItem
from sentence_transformers import SentenceTransformer, util
from transformers import pipeline


# 1. ëª¨ë¸ ë¡œë”© (FastAPI ì‹œìž‘ ì‹œ 1íšŒ)
model = SentenceTransformer('jhgan/ko-sbert-nli')
generator = pipeline('text-generation', model='EleutherAI/polyglot-ko-1.3b', tokenizer='EleutherAI/polyglot-ko-1.3b')    # íŒŒì´í”„ ë¼ì¸ ì‚¬ìš©


# 2. ë¬¸ìž¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ëŠ” í•¨ìˆ˜
def split_sentences(text: str) -> List[str]:
    return [s.strip() for s in text.split('.') if s.strip()]


# 3. ìƒì„±ëœ LLM ê²°ê³¼ì—ì„œ ì¶”ì²œ ë¬¸ìž¥ + ì´ìœ  ì¶”ì¶œ

def parse_generated_result(text: str) -> Tuple[str, str]:
    recommendation, reason = '', ''

    try:
        rec_match = re.search(r"ì¶”ì²œ ë¬¸ìž¥[:ï¼š]\s*(.+)", text)
        reason_match = re.search(r"ì´ìœ [:ï¼š]\s*(.+)", text)

        if rec_match:
            recommendation = rec_match.group(1).strip()
        if reason_match:
            reason = reason_match.group(1).strip()

    except Exception as e:
        print("[âŒ íŒŒì‹± ì˜¤ë¥˜]", e)
        print("[ðŸ“„ ì›ë³¸ ì‘ë‹µ]", text)

    return recommendation, reason




# 4. ìµœì¢… ë¶„ì„ í•¨ìˆ˜
def analyze_similarity(cover_letter: str, job_description: str) -> List[FeedbackItem]:
    sentences = split_sentences(cover_letter)
    jd_embedding = model.encode(job_description, convert_to_tensor=True)
    
    feedbacks = []
    prompts = []
    weak_indexes = []
    
    for i, sentence in enumerate(sentences):
        sentence_embedding = model.encode(sentence, convert_to_tensor=True)
        score = float(util.cos_sim(sentence_embedding, jd_embedding)[0][0])
        is_weak = score < 0.7    # ê¸°ì¤€ ê°’ ì¡°ì • ê°€ëŠ¥

        feedback = FeedbackItem(
            original_sentence=sentence,
            similarity_score=score,
            is_weak=is_weak,
            recommendation="",
            reason=""
        )
        
        if is_weak:    # ìœ ì‚¬ë„ê°€ ë‚®ìœ¼ë©´
            prompt = f"""
                    [ì§ë¬´ ì„¤ëª…]
                    {job_description}
                    
                    [ìžê¸°ì†Œê°œì„œ ë¬¸ìž¥]
                    {sentence}
                    
                    ì´ ë¬¸ìž¥ì´ ì§ë¬´ì— ì í•©í•˜ì§€ ì•Šë‹¤ë©´, ë” ì ì ˆí•œ ë¬¸ìž¥ìœ¼ë¡œ ê³ ì³ì£¼ì‹œê³  ê·¸ ì´ìœ ë„ ì„¤ëª…í•´ì£¼ì„¸ìš”.

                    ë‹¤ìŒ í˜•ì‹ì— ë§žì¶°ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”:

                    ì¶”ì²œ ë¬¸ìž¥:
                    ì´ìœ :
                    """
        
            # ìœ„ì˜ ì¶”ì²œ ë¬¸ìž¥ ë°›ëŠ” í¬ë§·ì„ ë¬¸ìž¥ ë§ˆë‹¤ ìƒì„±í•  ìˆ˜ ìžˆë„ë¡ ë¦¬ìŠ¤íŠ¸ì— ë„£ì–´ì£¼ê¸°
            prompts.append(prompt)
            weak_indexes.append(len(feedbacks))    # ê³ ì¹œ ë¬¸ìž¥ ìœ„ì¹˜ ì¶”ì 
        
        feedbacks.append(feedback)
        
    # ì•½í•œ ë¬¸ìž¥ë§Œ LLMìœ¼ë¡œ ì¶”ì²œ ìƒì„±
    if prompts:
        results = generator(
            prompts,
            max_new_tokens=80,
            do_sample=True,
            temperature=0.8,
            truncation=True
        )

        for idx, result in zip(weak_indexes, results):
            # generator(...) ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            gen_text = result[0]["generated_text"]
            print(gen_text)

            # JSON í˜•íƒœë¡œ íŒŒì‹±
            rec, reason = parse_generated_result(gen_text)

            # í•´ë‹¹ ìœ„ì¹˜ì˜ feedback ê°ì²´ì— ì €ìž¥
            feedbacks[idx].recommendation = rec
            feedbacks[idx].reason = reason

    return feedbacks